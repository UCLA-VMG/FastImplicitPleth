{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import commentjson as json\n",
    "import imageio.v2 as iio2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import tinycudann as tcnn\n",
    "import argparse\n",
    "\n",
    "from implicitpleth.models.siren import Siren\n",
    "from implicitpleth.models.combinations import MotionNet\n",
    "from implicitpleth.data.datasets import VideoGridDataset\n",
    "from implicitpleth.utils.utils import Dict2Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./configs/delta_motion.json\") as f:\n",
    "    json_config = json.load(f)\n",
    "_trial = 'v_99_2'\n",
    "json_config[\"video_path\"] = f'/home/pradyumnachari/Documents/ImplicitPPG/SIGGRAPH_Data/rgb_files/{_trial}'\n",
    "json_config[\"verbose\"] = True\n",
    "json_config[\"append_save_path\"] = None\n",
    "json_config[\"append_load_path\"] = None\n",
    "\n",
    "args = Dict2Class(json_config)\n",
    "args.spatiotemporal_device = torch.device(args.spatiotemporal_device)\n",
    "args.deltaspatial_device = torch.device(args.deltaspatial_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MotionNet(args.spatiotemporal_encoding, args.spatiotemporal_network,\n",
    "                  args.deltaspatial_encoding, args.deltaspatial_network)\n",
    "model.set_device(args.spatiotemporal_device, args.deltaspatial_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1 = torch.optim.Adam(model.xyt_to_d_enc.parameters(), lr=args.opt[\"lr\"],\n",
    "                       betas=(args.opt[\"beta1\"], args.opt[\"beta2\"]), eps=args.opt[\"eps\"])\n",
    "opt2 = torch.optim.Adam(model.xyt_to_d_net.parameters(), lr=args.opt[\"lr\"], #weight_decay=1e-6,\n",
    "                       betas=(args.opt[\"beta1\"], args.opt[\"beta2\"]), eps=args.opt[\"eps\"])\n",
    "opt3 = torch.optim.Adam(model.d_to_rgb_enc.parameters(), lr=args.opt[\"lr\"],\n",
    "                       betas=(args.opt[\"beta1\"], args.opt[\"beta2\"]), eps=args.opt[\"eps\"])\n",
    "opt4 = torch.optim.Adam(model.d_to_rgb_net.parameters(), lr=args.opt[\"lr\"], #weight_decay=1e-6,\n",
    "                       betas=(args.opt[\"beta1\"], args.opt[\"beta2\"]), eps=args.opt[\"eps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.append_save_path is not None:\n",
    "    args.trace[\"folder\"] =  args.trace[\"folder\"] + args.append_save_path\n",
    "    args.checkpoints[\"dir\"] =  args.checkpoints[\"dir\"] + args.append_save_path\n",
    "if args.trace[\"folder\"] is not None:\n",
    "    os.makedirs(args.trace[\"folder\"], exist_ok=True)\n",
    "    if args.verbose: print(f'Saving trace to {args.trace[\"folder\"]}')\n",
    "if args.checkpoints[\"save\"]:\n",
    "    os.makedirs(args.checkpoints[\"dir\"], exist_ok=True)\n",
    "    if args.verbose: print(f'Saving checkpoints to {args.checkpoints[\"dir\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = args.train[\"epochs\"]\n",
    "ndigits_epoch = int(np.log10(epochs)+1)\n",
    "latest_ckpt_path = os.path.join(args.checkpoints[\"dir\"], args.checkpoints[\"latest\"])\n",
    "if os.path.exists(latest_ckpt_path):\n",
    "    if args.verbose: print('Loading latest checkpoint...')\n",
    "    saved_dict = torch.load(latest_ckpt_path)\n",
    "    model.load_state_dict(saved_dict[\"model_state_dict\"])\n",
    "    # if \"optimizer_state_dict\" in saved_dict.keys():\n",
    "    #     opt.load_state_dict(saved_dict[\"optimizer_state_dict\"])\n",
    "    start_epoch = saved_dict[\"epoch\"] + 1\n",
    "    if args.verbose: print(f'Continuing from epoch {start_epoch}.')\n",
    "else:\n",
    "    if args.verbose: print('Start from scratch.')\n",
    "    start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = VideoGridDataset(args.video_path, verbose=args.verbose, num_frames=args.data[\"num_frames\"], \n",
    "                        start_frame=args.data[\"start_frame\"], pixel_norm=args.data[\"norm_value\"])\n",
    "dloader = torch.utils.data.DataLoader(range(len(dset)), batch_size=args.data[\"batch_size\"], shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "for epoch in range(start_epoch,epochs+1):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for count, item in tqdm(enumerate(dloader),total=len(dloader)):\n",
    "        loc = dset.loc[item].half()\n",
    "        pixel = dset.vid[item].half()\n",
    "        output, _ = model(loc)\n",
    "        # Since the model takes care of moving the data to different devices, move GT correspondingly.\n",
    "        pixel = pixel.to(output.dtype).to(output.device)\n",
    "        # Backpropagation.\n",
    "        opt1.zero_grad()\n",
    "        opt2.zero_grad()\n",
    "        opt3.zero_grad()\n",
    "        opt4.zero_grad()\n",
    "        l2_error = (output - pixel)**2\n",
    "        loss = l2_error.mean()\n",
    "        loss.backward()\n",
    "        opt1.step()\n",
    "        opt2.step()\n",
    "        opt3.step()\n",
    "        opt4.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch: {epoch}, Loss: {train_loss/len(dloader)}', flush=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        trace_loc = dset.loc.half()\n",
    "        trace, _ = model(trace_loc)\n",
    "        trace = trace.detach().cpu().float().reshape(dset.shape).permute(2,0,1,3).numpy()\n",
    "        trace = (np.clip(trace, 0, 1)*255).astype(np.uint8)\n",
    "        save_path = os.path.join(args.trace[\"folder\"], f'{args.trace[\"file_tag\"]}{str(epoch).zfill(ndigits_epoch)}.avi')\n",
    "        iio2.mimwrite(save_path, trace, fps=30)\n",
    "        save_path = os.path.join(args.trace[\"folder\"], f'slow_{args.trace[\"file_tag\"]}{str(epoch).zfill(ndigits_epoch)}.avi')\n",
    "        iio2.mimwrite(save_path, trace)\n",
    "    if args.checkpoints[\"save\"]:\n",
    "        if args.verbose: print('Saving checkpoint.')\n",
    "        if epoch % args.checkpoints[\"epoch_frequency\"] == 0:\n",
    "            checkpoint_file = f'{args.checkpoints[\"file_tag\"]}{str(epoch).zfill(ndigits_epoch)}{args.checkpoints[\"ext\"]}'\n",
    "            # Save as dict to maintain uniformity\n",
    "            torch.save({'model_state_dict': model.state_dict()}, \n",
    "                        os.path.join(args.checkpoints[\"dir\"], checkpoint_file))\n",
    "            if args.verbose: print(f'Saved model for epoch {epoch}.')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            # 'optimizer_state_dict': opt.state_dict(),\n",
    "            }, latest_ckpt_path)\n",
    "        if args.verbose: print('Saved latest checkpoint.')\n",
    "    # Epoch demarcation\n",
    "    print('-'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hashppg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b310efec2753918fc2ffe1b7b62e4629d4af86145c6b3c505a1f8291347894dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
