{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import commentjson as json\n",
    "import imageio.v2 as iio2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import tinycudann as tcnn\n",
    "import argparse\n",
    "\n",
    "from implicitpleth.models.siren import Siren\n",
    "from implicitpleth.models.combinations import MotionNet\n",
    "from implicitpleth.data.datasets import VideoGridDataset\n",
    "from implicitpleth.utils.utils import Dict2Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./configs/delta_motion.json\") as f:\n",
    "    json_config = json.load(f)\n",
    "\n",
    "json_config[\"video_path\"] = \"./assets/v_84_2.avi\"\n",
    "json_config[\"verbose\"] = True\n",
    "json_config[\"append_save_path\"] = None\n",
    "json_config[\"append_load_path\"] = None\n",
    "args = Dict2Class(json_config)\n",
    "args.spatiotemporal_device = torch.device(args.spatiotemporal_device)\n",
    "args.deltaspatial_device = torch.device(args.deltaspatial_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MotionNet(args.spatiotemporal_encoding, args.spatiotemporal_network,\n",
    "                  args.deltaspatial_encoding, args.deltaspatial_network)\n",
    "model.set_device(args.spatiotemporal_device, args.deltaspatial_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=args.opt[\"lr\"],\n",
    "                       betas=(args.opt[\"beta1\"], args.opt[\"beta2\"]), eps=args.opt[\"eps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.append_save_path is not None:\n",
    "    args.trace[\"folder\"] =  args.trace[\"folder\"] + args.append_save_path\n",
    "    args.checkpoints[\"dir\"] =  args.checkpoints[\"dir\"] + args.append_save_path\n",
    "if args.trace[\"folder\"] is not None:\n",
    "    os.makedirs(args.trace[\"folder\"], exist_ok=True)\n",
    "    if args.verbose: print(f'Saving trace to {args.trace[\"folder\"]}')\n",
    "if args.checkpoints[\"save\"]:\n",
    "    os.makedirs(args.checkpoints[\"dir\"], exist_ok=True)\n",
    "    if args.verbose: print(f'Saving checkpoints to {args.checkpoints[\"dir\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = args.train[\"epochs\"]\n",
    "ndigits_epoch = int(np.log10(epochs)+1)\n",
    "latest_ckpt_path = os.path.join(args.checkpoints[\"dir\"], args.checkpoints[\"latest\"])\n",
    "if os.path.exists(latest_ckpt_path):\n",
    "    if args.verbose: print('Loading latest checkpoint...')\n",
    "    saved_dict = torch.load(latest_ckpt_path)\n",
    "    model.load_state_dict(saved_dict[\"model_state_dict\"])\n",
    "    if \"optimizer_state_dict\" in saved_dict.keys():\n",
    "        opt.load_state_dict(saved_dict[\"optimizer_state_dict\"])\n",
    "    start_epoch = saved_dict[\"epoch\"] + 1\n",
    "    if args.verbose: print(f'Continuing from epoch {start_epoch}.')\n",
    "else:\n",
    "    if args.verbose: print('Start from scratch.')\n",
    "    start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, T = np.meshgrid(np.arange(128),np.arange(128),np.arange(300))\n",
    "\n",
    "X = (X.ravel() / 128) - 0.5\n",
    "Y = (Y.ravel() / 128) - 0.5\n",
    "T = (T.ravel() / 300) - 0.5\n",
    "\n",
    "trace_loc = torch.tensor(np.stack((X,Y,T), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = VideoGridDataset(args.video_path, verbose=args.verbose, num_frames=args.data[\"num_frames\"], \n",
    "                        start_frame=args.data[\"start_frame\"], pixel_norm=args.data[\"norm_value\"])\n",
    "dloader = torch.utils.data.DataLoader(range(len(dset)), batch_size=args.data[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch,epochs+1):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for count, item in tqdm(enumerate(dloader),total=len(dloader)):\n",
    "        loc = dset.loc[item].half()\n",
    "        pixel = dset.vid[item].half()\n",
    "        output, _ = model(loc)\n",
    "        # Since the model takes care of moving the data to different devices, move GT correspondingly.\n",
    "        pixel = pixel.to(output.dtype).to(output.device)\n",
    "        # Backpropagation.\n",
    "        opt.zero_grad()\n",
    "        l2_error = (output - pixel)**2\n",
    "        loss = l2_error.mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch: {epoch}, Loss: {train_loss/len(dloader)}', flush=True)\n",
    "    with torch.no_grad():\n",
    "        trace, _ = model(trace_loc)\n",
    "        trace = trace.detach().cpu().float().reshape(dset.shape).permute(2,0,1,3).numpy()\n",
    "        trace = (np.clip(trace, 0, 1)*255).astype(np.uint8)\n",
    "        save_path = os.path.join(args.trace[\"folder\"], f'{args.trace[\"file_tag\"]}{str(epoch).zfill(ndigits_epoch)}.avi')\n",
    "        iio2.mimwrite(save_path, trace, fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hashppg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b310efec2753918fc2ffe1b7b62e4629d4af86145c6b3c505a1f8291347894dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
