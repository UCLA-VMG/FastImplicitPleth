{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D9s_s2wj-eI"
      },
      "source": [
        "# Python code starts here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlPV8Ajddobz",
        "outputId": "fc2f0975-1463-48ee-be5f-cd93fbc2a5b7"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "import scipy.signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PhysNet_padding_Encoder_Decoder_MAX(torch.nn.Module):\n",
        "    def __init__(self, frames=64, channels=3):  \n",
        "        super(PhysNet_padding_Encoder_Decoder_MAX, self).__init__()\n",
        "        \n",
        "        self.ConvBlock1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(channels, 16, [1,5,5],stride=1, padding=[0,2,2]),\n",
        "            torch.nn.BatchNorm3d(16),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.ConvBlock2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(16, 32, [3, 3, 3], stride=1, padding=1),\n",
        "            torch.nn.BatchNorm3d(32),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.ConvBlock3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(32, 64, [3, 3, 3], stride=1, padding=1),\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        self.ConvBlock4 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(64, 64, [3, 3, 3], stride=1, padding=1),\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.ConvBlock5 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(64, 64, [3, 3, 3], stride=1, padding=1),\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.ConvBlock6 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(64, 64, [3, 3, 3], stride=1, padding=1),\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.ConvBlock7 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(64, 64, [3, 3, 3], stride=1, padding=1),\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.ConvBlock8 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(64, 64, [3, 3, 3], stride=1, padding=1),\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.ConvBlock9 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(64, 64, [3, 3, 3], stride=1, padding=1),\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        self.upsample = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(in_channels=64, out_channels=64, kernel_size=[4,1,1], stride=[2,1,1], padding=[1,0,0]),   #[1, 128, 32]\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ELU(),\n",
        "        )\n",
        "        self.upsample2 = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(in_channels=64, out_channels=64, kernel_size=[4,1,1], stride=[2,1,1], padding=[1,0,0]),   #[1, 128, 32]\n",
        "            torch.nn.BatchNorm3d(64),\n",
        "            torch.nn.ELU(),\n",
        "        )\n",
        " \n",
        "        self.ConvBlock10 = torch.nn.Conv3d(64, 1, [1,1,1],stride=1, padding=0)\n",
        "        \n",
        "        self.MaxpoolSpa = torch.nn.MaxPool3d((1, 2, 2), stride=(1, 2, 2))\n",
        "        self.MaxpoolSpaTem = torch.nn.MaxPool3d((2, 2, 2), stride=2)\n",
        "        \n",
        "        \n",
        "        #self.poolspa = torch.nn.AdaptiveMaxPool3d((frames,1,1))    # pool only spatial space \n",
        "        self.poolspa = torch.nn.AdaptiveAvgPool3d((frames,1,1))\n",
        "\n",
        "        \n",
        "    def forward(self, x):\t    \t# x [3, T, 128,128]\n",
        "        x_visual = x\n",
        "        [batch,channel,length,width,height] = x.shape\n",
        "        # print(length)\n",
        "        # print(torch.mean(x, dim=(1,2,3,4)))\n",
        "          \n",
        "        x = self.ConvBlock1(x)\t\t     # x [3, T, 128,128]\n",
        "        x = self.MaxpoolSpa(x)       # x [16, T, 64,64]\n",
        "\n",
        "        # print(torch.mean(x, dim=(1,2,3,4)))\n",
        "\n",
        "        x = self.ConvBlock2(x)\t\t    # x [32, T, 64,64]\n",
        "        x_visual6464 = self.ConvBlock3(x)\t    \t# x [32, T, 64,64]\n",
        "        x = self.MaxpoolSpaTem(x_visual6464)      # x [32, T/2, 32,32]    Temporal halve\n",
        "\n",
        "        x = self.ConvBlock4(x)\t\t    # x [64, T/2, 32,32]\n",
        "        x_visual3232 = self.ConvBlock5(x)\t    \t# x [64, T/2, 32,32]\n",
        "        x = self.MaxpoolSpaTem(x_visual3232)      # x [64, T/4, 16,16]\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = self.ConvBlock6(x)\t\t    # x [64, T/4, 16,16]\n",
        "        x_visual1616 = self.ConvBlock7(x)\t    \t# x [64, T/4, 16,16]\n",
        "        x = self.MaxpoolSpa(x_visual1616)      # x [64, T/4, 8,8]\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = self.ConvBlock8(x)\t\t    # x [64, T/4, 8, 8]\n",
        "        x = self.ConvBlock9(x)\t\t    # x [64, T/4, 8, 8]\n",
        "        x = self.upsample(x)\t\t    # x [64, T/2, 8, 8]\n",
        "        x = self.upsample2(x)\t\t    # x [64, T, 8, 8]\n",
        "\n",
        "        # print(x.shape)\n",
        "        \n",
        "        x = self.poolspa(x)     # x [64, T, 1,1]    -->  groundtruth left and right - 7 \n",
        "        x = self.ConvBlock10(x)    # x [1, T, 1,1]\n",
        "\n",
        "        # print(x.shape)\n",
        "        # print(torch.mean(x, dim=(1,2,3,4)))\n",
        "\n",
        "        \n",
        "        rPPG = x.view(-1,length)            \n",
        "\n",
        "        return rPPG, x_visual, x_visual3232, x_visual1616"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1H2MspBw_Ck"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, video_filename=\"output/ref.avi\", n_frames=300, sequence_length = 64):\n",
        "    model.eval()#!!!\n",
        "    print(f\"Reading: {video_filename}\")\n",
        "    frames = np.array(imageio.mimread(video_filename))[:n_frames]\n",
        "    cur_est_ppgs = None\n",
        "    with torch.no_grad():\n",
        "        for cur_frame_num in range(frames.shape[0]):\n",
        "            cur_frame = frames[cur_frame_num, :, :, :]\n",
        "            # Preprocess\n",
        "            cur_frame_cropped = torch.from_numpy(cur_frame.astype(np.uint8)).permute(2, 0, 1).float()\n",
        "            cur_frame_cropped = cur_frame_cropped / 255\n",
        "            cur_frame_cropped = cur_frame_cropped.unsqueeze(0).cuda() # Add the T dim\n",
        "            # Concat\n",
        "            if cur_frame_num % sequence_length == 0:\n",
        "                cur_cat_frames = cur_frame_cropped\n",
        "            else:\n",
        "                cur_cat_frames = torch.cat((cur_cat_frames, cur_frame_cropped), 0)\n",
        "\n",
        "            # Test the performance\n",
        "            if cur_cat_frames.shape[0] == sequence_length:\n",
        "                # DL\n",
        "                cur_cat_frames = cur_cat_frames.unsqueeze(0) # Add the B dim\n",
        "                cur_cat_frames = torch.transpose(cur_cat_frames, 1, 2)\n",
        "                cur_est_ppg, _, _, _ = model(cur_cat_frames)\n",
        "                cur_est_ppg = cur_est_ppg.squeeze().cpu().numpy()\n",
        "            # First seq\n",
        "                if cur_est_ppgs is None: \n",
        "                    cur_est_ppgs = cur_est_ppg\n",
        "                else:\n",
        "                    cur_est_ppgs = np.concatenate((cur_est_ppgs, cur_est_ppg), -1)\n",
        "    est_hr = prpsd2(cur_est_ppgs-np.mean(cur_est_ppgs), 30, 45, 150, BUTTER_ORDER=6, DETREND=False)\n",
        "    print(f\"Estimated HR: {est_hr}\")\n",
        "    return cur_est_ppgs\n",
        "\n",
        "def prpsd2(BVP, FS, LL_PR, UL_PR, BUTTER_ORDER=6, DETREND=False, PlotTF=False, FResBPM = 0.1, RECT=True):\n",
        "    '''\n",
        "    Estimates pulse rate from the power spectral density a BVP signal\n",
        "    \n",
        "    Inputs\n",
        "        BVP              : A BVP timeseries. (1d numpy array)\n",
        "        fs               : The sample rate of the BVP time series (Hz/fps). (int)\n",
        "        lower_cutoff_bpm : The lower limit for pulse rate (bpm). (int)\n",
        "        upper_cutoff_bpm : The upper limit for pulse rate (bpm). (int)\n",
        "        butter_order     : Order of the Butterworth Filter. (int)\n",
        "        detrend          : Detrend the input signal. (bool)\n",
        "        FResBPM          : Resolution (bpm) of bins in power spectrum used to determine pulse rate and SNR. (float)\n",
        "    \n",
        "    Outputs\n",
        "        pulse_rate       : The estimated pulse rate in BPM. (float)\n",
        "    \n",
        "    Daniel McDuff, Ethan Blackford, January 2019\n",
        "    Copyright (c)\n",
        "    Licensed under the MIT License and the RAIL AI License.\n",
        "    '''\n",
        "\n",
        "    N = (60*FS)/FResBPM\n",
        "\n",
        "    # Detrending + nth order butterworth + periodogram\n",
        "    if DETREND:\n",
        "        BVP = detrend(np.cumsum(BVP), 100)\n",
        "    if BUTTER_ORDER:\n",
        "        [b, a] = scipy.signal.butter(BUTTER_ORDER, [LL_PR/60, UL_PR/60], btype='bandpass', fs = FS)\n",
        "    \n",
        "    BVP = scipy.signal.filtfilt(b, a, np.double(BVP))\n",
        "    \n",
        "    # Calculate the PSD and the mask for the desired range\n",
        "    if RECT:\n",
        "        F, Pxx = scipy.signal.periodogram(x=BVP,  nfft=N, fs=FS, detrend=False);  \n",
        "    else:\n",
        "        F, Pxx = scipy.signal.periodogram(x=BVP, window=np.hanning(len(BVP)), nfft=N, fs=FS)\n",
        "    FMask = (F >= (LL_PR/60)) & (F <= (UL_PR/60))\n",
        "    \n",
        "    # Calculate predicted pulse rate:\n",
        "    FRange = F * FMask\n",
        "    PRange = Pxx * FMask\n",
        "    MaxInd = np.argmax(PRange)\n",
        "    pulse_rate_freq = FRange[MaxInd]\n",
        "    pulse_rate = pulse_rate_freq*60\n",
        "\n",
        "    # Optionally Plot the PSD and peak frequency\n",
        "    if PlotTF:\n",
        "        # Plot PSD (in dB) and peak frequency\n",
        "        plt.figure()\n",
        "        plt.plot(F, 10 * np.log10(Pxx))\n",
        "        plt.plot(pulse_rate_freq, 10 * np.log10(PRange[MaxInd]),'ro')\n",
        "        plt.xlabel('Frequency (Hz)')\n",
        "        plt.ylabel('Power (dB)')\n",
        "        plt.xlim([0, 4.5])\n",
        "        plt.title('Power Spectrum and Peak Frequency')\n",
        "            \n",
        "    return pulse_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDuFzSqVZrGa",
        "outputId": "3e4a4b25-e7ac-40d8-cf78-4747ccababed"
      },
      "outputs": [],
      "source": [
        "model = PhysNet_padding_Encoder_Decoder_MAX(frames=64, channels=3).to(device)\n",
        "model.load_state_dict(torch.load(f\"assets/PhysNet_state_dict_best.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT = '/home/pradyumnachari/Documents/ImplicitPPG/SIGGRAPH_Data/rgb_files/'\n",
        "_trial = 'v_93_6'\n",
        "plt.imshow(imageio.v2.imread(os.path.join(ROOT,_trial,\"rgbd_rgb_0.png\")))\n",
        "plt.show()\n",
        "print(os.path.join(ROOT,_trial,\"rgbd_ppg.npy\"))\n",
        "gt_ppg = np.load(os.path.join(ROOT,_trial,\"rgbd_ppg.npy\"))[:300]\n",
        "gt_hr = prpsd2(gt_ppg-np.mean(gt_ppg), 30, 45, 150, BUTTER_ORDER=6, DETREND=False)\n",
        "print(f\"GT: {gt_hr}\")\n",
        "plt.figure()\n",
        "plt.plot(gt_ppg)\n",
        "plt.title('GT PPG')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = eval_model(model, f\"temp.avi\", 300)\n",
        "plt.plot(temp)\n",
        "plt.show()\n",
        "print('-'*100)\n",
        "pleth = eval_model(model, f\"pleth.avi\", 300)\n",
        "plt.plot(pleth)\n",
        "plt.show()\n",
        "print('-'*100)\n",
        "pleth = np.array(imageio.v2.mimread(\"pleth.avi\")).mean(1).mean(1)[:,1]\n",
        "pleth_hr = prpsd2(pleth-np.mean(pleth), 30, 45, 150, BUTTER_ORDER=6, DETREND=False)\n",
        "print(pleth_hr)\n",
        "plt.plot(pleth)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orig_est=[0]\n",
        "# orig_est = eval_model(model, f\"assets/v_101_2.avi\", 300)\n",
        "# orig_est = orig_est - orig_est.min()\n",
        "# orig_est = orig_est / orig_est.max()\n",
        "print('-'*100)\n",
        "gt_ppg = np.load(os.path.join(ROOT,_trial,\"rgbd_ppg.npy\"))[:300]\n",
        "gt_ppg = gt_ppg - gt_ppg.min()\n",
        "gt_ppg = gt_ppg / gt_ppg.max()\n",
        "start_epoch = 1\n",
        "end_epoch = 5\n",
        "for i in range(start_epoch,end_epoch+1):\n",
        "    new_est = eval_model(model, f\"residual/epoch_{i:03d}.avi\", 300)\n",
        "    new_est = new_est - new_est.min()\n",
        "    new_est = new_est / new_est.max()\n",
        "    motion_est = eval_model(model, f\"residual/motion_epoch_{i:03d}.avi\", 300)\n",
        "    motion_est = motion_est - motion_est.min()\n",
        "    motion_est = motion_est / motion_est.max()\n",
        "    rescaled_residual = eval_model(model, f\"residual/rescaled_residual_epoch_{i:03d}.avi\", 300)\n",
        "    rescaled_residual = rescaled_residual - rescaled_residual.min()\n",
        "    rescaled_residual = rescaled_residual / rescaled_residual.max()\n",
        "\n",
        "    pleth = np.array(imageio.v2.mimread(f'residual/rescaled_residual_epoch_{i:03d}.avi'))\n",
        "    pleth = pleth.mean(1).mean(1)[:,1]\n",
        "    pleth_hr = prpsd2(pleth-np.mean(pleth), 30, 45, 150, BUTTER_ORDER=6, DETREND=False)\n",
        "    print(pleth_hr)\n",
        "    pleth = pleth - pleth.min()\n",
        "    pleth = pleth / pleth.max()\n",
        "    pleth_hr = prpsd2(pleth-np.mean(pleth), 30, 45, 150, BUTTER_ORDER=6, DETREND=False)\n",
        "    print(pleth_hr)\n",
        "\n",
        "    plt.figure(figsize=(30,5))\n",
        "    plt.plot(gt_ppg, label=\"GT\")\n",
        "    plt.plot(orig_est, label=\"orig\")\n",
        "    plt.plot(new_est, label=\"new\")\n",
        "    plt.plot(motion_est, label=\"motion\")\n",
        "    plt.plot(pleth, label=\"green\")\n",
        "    plt.title('Estimated PPG')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    print('-'*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print('-'*100)\n",
        "# gt_ppg = np.load(os.path.join(ROOT,_trial,\"rgbd_ppg.npy\"))[:300]\n",
        "# gt_ppg = gt_ppg - gt_ppg.min()\n",
        "# gt_ppg = gt_ppg / gt_ppg.max()\n",
        "# start_epoch = 1\n",
        "# end_epoch = 10\n",
        "# for i in range(start_epoch,end_epoch+1):\n",
        "\n",
        "#     new_est = eval_model(model, f\"delta_motion/epoch_{i:03d}.avi\", 300)\n",
        "#     new_est = new_est - new_est.min()\n",
        "#     new_est = new_est / new_est.max()\n",
        "#     plt.figure(figsize=(30,5))\n",
        "#     plt.plot(gt_ppg, label=\"GT\")\n",
        "#     plt.plot(new_est, label=\"new\")\n",
        "#     plt.title('Estimated PPG')\n",
        "#     plt.legend()\n",
        "#     plt.show()\n",
        "    \n",
        "#     print('-'*100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hashppg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "b310efec2753918fc2ffe1b7b62e4629d4af86145c6b3c505a1f8291347894dd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
