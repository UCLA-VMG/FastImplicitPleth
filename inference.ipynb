{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import commentjson as json\n",
    "import imageio.v2 as iio2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import tinycudann as tcnn\n",
    "import argparse\n",
    "\n",
    "from utils import Dict2Class, CNN3D, VideoGridDataset, prpsd2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config.\n",
    "with open(\"./configs/residual_plethysmograph.json\") as f:\n",
    "    json_config = json.load(f)\n",
    "\n",
    "# Essential config params\n",
    "json_config[\"verbose\"] = True\n",
    "\n",
    "# Convert the dictionary to a class to mimic argparser\n",
    "args = Dict2Class(json_config)\n",
    "# Torch Device\n",
    "args.pleth_device = torch.device(args.pleth_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pleth Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pleth_enc = tcnn.Encoding(args.pleth_encoding[\"input_dims\"], args.pleth_encoding)\n",
    "pleth_net = tcnn.Network(pleth_enc.n_output_dims, args.pleth_network[\"output_dims\"], args.pleth_network)\n",
    "pleth_model = torch.nn.Sequential(pleth_enc, pleth_net)\n",
    "pleth_model.to(args.pleth_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the same device as the pleth. This can be if there is a lack of GPU memory.\n",
    "mask_model = CNN3D(frames=64, sidelen = 128, channels=6).to(args.pleth_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Query Grid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Set the path and other params here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"./assets/vid.avi\"\n",
    "num_frames = 300\n",
    "start_frame = 0\n",
    "\n",
    "gt_path = './assets/ppg.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = VideoGridDataset(video_path, verbose=True, num_frames=num_frames, \n",
    "                        start_frame=start_frame, pixel_norm=255)\n",
    "trace_loc = dset.loc.to(args.pleth_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Paths to load models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pleth_model_path = \"./residual_plethysmograph/epoch_5.pth\"\n",
    "mask_model_path = \"./assets/mask_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pleth_model.load_state_dict(torch.load(pleth_model_path)['model_state_dict'])\n",
    "mask_model.load_state_dict(torch.load(mask_model_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query and Generate the Residual Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pleth_tensor = pleth_model(trace_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pleth_tensor = pleth_tensor.reshape(*dset.shape).permute(2,0,1,3).unsqueeze(0)\n",
    "print(pleth_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_tensor = dset.vid.to(args.pleth_device)\n",
    "vid_tensor = vid_tensor.reshape(*dset.shape).permute(2,0,1,3).unsqueeze(0)\n",
    "print(vid_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_to_model = torch.cat((vid_tensor, pleth_tensor), dim=-1)\n",
    "# Due to a compute limit, the model was only trained on the first 64 frames.\n",
    "mask = mask_model(inp_to_model[:,0:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pleth_full_vid_npy = pleth_tensor.detach().cpu().numpy()[0]\n",
    "mask_npy = mask.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_npy)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a detrend Function\n",
    "\n",
    "Based on the rPPG_Toolbox detrend function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def utils_detrend(input_signal, lambda_value):\n",
    "    signal_length = input_signal.shape[0]\n",
    "    # observation matrix\n",
    "    H = np.identity(signal_length)\n",
    "    ones = np.ones(signal_length)\n",
    "    minus_twos = -2 * np.ones(signal_length)\n",
    "    diags_data = np.array([ones, minus_twos, ones])\n",
    "    diags_index = np.array([0, 1, 2])\n",
    "    D = sparse.spdiags(diags_data, diags_index,\n",
    "                (signal_length - 2), signal_length).toarray()\n",
    "    filtered_signal = np.dot(\n",
    "        (H - np.linalg.inv(H + (lambda_value ** 2) * np.dot(D.T, D))), input_signal)\n",
    "    return filtered_signal\n",
    "\n",
    "def detrend_signal(BVP, fs=30):\n",
    "    BVP = np.reshape(BVP,(1,-1))\n",
    "    BVP = utils_detrend(np.mat(BVP).H, 100)\n",
    "    BVP = np.asarray(np.transpose(BVP))[0]\n",
    "    return BVP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Green Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeen_est = pleth_full_vid_npy[...,1].mean(1).mean(1)\n",
    "greeen_est = detrend_signal(greeen_est)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(greeen_est)\n",
    "plt.title(\"Green Estimate\")\n",
    "plt.show()\n",
    "print(f\"Predicted Heart Rate: {prpsd2(greeen_est-np.mean(greeen_est), FS=30, LL_PR=45, UL_PR=180)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Green Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeen_masked_est = (pleth_full_vid_npy[...,1] * mask_npy).sum(1).sum(1) / mask_npy.sum(0).sum(0)\n",
    "greeen_est = detrend_signal(greeen_masked_est)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(greeen_masked_est)\n",
    "plt.title(\"Green Masked Estimate\")\n",
    "plt.show()\n",
    "print(f\"Predicted Heart Rate: {prpsd2(greeen_masked_est-np.mean(greeen_masked_est), FS=30, LL_PR=45, UL_PR=180)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load(gt_path)\n",
    "# We process in chunks of 300\n",
    "# If the default values were used, then only the first 300 samples were processed\n",
    "gt = gt[start_frame : start_frame+num_frames]\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(gt)\n",
    "plt.title(\"Green Estimate\")\n",
    "plt.show()\n",
    "print(f\"Predicted Heart Rate: {prpsd2(gt-np.mean(gt), FS=30, LL_PR=45, UL_PR=180)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hashppg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b310efec2753918fc2ffe1b7b62e4629d4af86145c6b3c505a1f8291347894dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
